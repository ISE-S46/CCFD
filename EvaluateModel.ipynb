{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af8e0dff-565b-4fe6-a0a7-db75184a53d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 555719\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import (\n",
    "    col, to_timestamp, hour, dayofweek,\n",
    "    to_date, datediff, floor,\n",
    "    radians, cos, sin, atan2, sqrt,\n",
    "    sum, count, when, lit, udf\n",
    ")\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "from pyspark.ml import PipelineModel\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "\n",
    "spark = SparkSession.builder.appName(\"EvaluatePipeline\").getOrCreate()\n",
    "\n",
    "df = spark.read.csv(\"fraudTest.csv\", header=True, inferSchema=True)\n",
    "print(f\"Total rows: {df.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8056c902-ef82-4b9f-b38d-a522da80f421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date/Time Features\n",
    "df = df.withColumn(\"trans_date_trans_time\", to_timestamp(col(\"trans_date_trans_time\"), \"yyyy-MM-dd HH:mm:ss\"))\n",
    "df = df.withColumn(\"hour\", hour(col(\"trans_date_trans_time\")))\n",
    "df = df.withColumn(\"day_of_week\", dayofweek(col(\"trans_date_trans_time\")))\n",
    "\n",
    "# Daily Spending/Transactions (Window functions)\n",
    "df = df.withColumn(\"trans_date_only\", to_date(col(\"trans_date_trans_time\")))\n",
    "\n",
    "window_spec_daily = Window.partitionBy(\"cc_num\", \"trans_date_only\")\n",
    "\n",
    "df = df.withColumn(\"daily_spending\", sum(\"amt\").over(window_spec_daily))\n",
    "df = df.withColumn(\"daily_transactions\", count(\"cc_num\").over(window_spec_daily))\n",
    "\n",
    "df = df.drop(\"trans_date_only\")\n",
    "\n",
    "# Haversine Distance\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371  # Earth radius in km\n",
    "    return 2 * R * atan2(\n",
    "        sqrt(sin((radians(lat2) - radians(lat1)) / 2) ** 2 +\n",
    "             cos(radians(lat1)) * cos(radians(lat2)) *\n",
    "             sin((radians(lon2) - radians(lon1)) / 2) ** 2),\n",
    "        sqrt(1 - (sin((radians(lat2) - radians(lat1)) / 2) ** 2 +\n",
    "                  cos(radians(lat1)) * cos(radians(lat2)) *\n",
    "                  sin((radians(lon2) - radians(lon1)) / 2) ** 2))\n",
    "    )\n",
    "\n",
    "df = df.withColumn(\"distance\", haversine(col(\"lat\"), col(\"long\"), col(\"merch_lat\"), col(\"merch_long\")))\n",
    "\n",
    "# Age Calculation\n",
    "df = df.withColumn(\"dob_date\", to_date(col(\"dob\")))\n",
    "df = df.withColumn(\"transaction_date\", to_date(col(\"trans_date_trans_time\")))\n",
    "df = df.withColumn(\"age\", floor(datediff(col(\"transaction_date\"), col(\"dob_date\")) / 365.25))\n",
    "df = df.drop(\"dob_date\", \"transaction_date\")\n",
    "\n",
    "# Class Weight (for handling imbalance)\n",
    "is_fraud_count = df.filter(col(\"is_fraud\") == 1).count()\n",
    "is_not_fraud_count = df.filter(col(\"is_fraud\") == 0).count()\n",
    "\n",
    "class_weight_for_fraud = is_not_fraud_count / is_fraud_count\n",
    "\n",
    "df = df.withColumn(\"class_weight\", when(col(\"is_fraud\") == 1, lit(class_weight_for_fraud)).otherwise(lit(1.0)))\n",
    "\n",
    "# Label preparation (cast to DoubleType, required for MLlib)\n",
    "df = df.withColumn(\"indexedLabel\", col(\"is_fraud\").cast(DoubleType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e22f7387-6dcf-44db-af55-02c5459f769f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------------------------------------+----------------------------------------+----------+----------------+\n",
      "|indexedLabel|rawPrediction                           |probability                             |prediction|tuned_prediction|\n",
      "+------------+----------------------------------------+----------------------------------------+----------+----------------+\n",
      "|0.0         |[0.8928531792839728,-0.8928531792839728]|[0.856400056381766,0.14359994361823403] |0.0       |0.0             |\n",
      "|0.0         |[1.5466820417606335,-1.5466820417606335]|[0.9566181885897809,0.04338181141021913]|0.0       |0.0             |\n",
      "|0.0         |[1.5466820417606335,-1.5466820417606335]|[0.9566181885897809,0.04338181141021913]|0.0       |0.0             |\n",
      "|0.0         |[1.5466820417606335,-1.5466820417606335]|[0.9566181885897809,0.04338181141021913]|0.0       |0.0             |\n",
      "|0.0         |[1.5466820417606335,-1.5466820417606335]|[0.9566181885897809,0.04338181141021913]|0.0       |0.0             |\n",
      "+------------+----------------------------------------+----------------------------------------+----------+----------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# Load the Trained Pipeline Model\n",
    "model_path = \"./Pipeline\"\n",
    "\n",
    "loaded_pipeline_model = PipelineModel.load(model_path)\n",
    "\n",
    "predictions = loaded_pipeline_model.transform(df)\n",
    "predictions.cache() # Cache for faster multiple evaluations\n",
    "\n",
    "chosen_threshold = 0.75 # Use the threshold you decided on during your analysis\n",
    "\n",
    "predict_at_threshold_udf = udf(lambda prob_vec: 1.0 if prob_vec[1] >= chosen_threshold else 0.0, DoubleType())\n",
    "\n",
    "# Add the new thresholded prediction column to the predictions DataFrame\n",
    "predictions_with_threshold = predictions.withColumn(\n",
    "    \"tuned_prediction\",\n",
    "    predict_at_threshold_udf(col(\"probability\"))\n",
    ")\n",
    "\n",
    "predictions_with_threshold.select(\"indexedLabel\", \"rawPrediction\", \"probability\", \"prediction\", \"tuned_prediction\").show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f3dc3ad-1b50-42b5-b20a-6c83a64bc747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area Under ROC (AUC-ROC): 0.9964\n",
      "Area Under PR (AUC-PR): 0.7652\n",
      "F1 Score (tuned threshold 0.75): 0.9947\n",
      "Precision (tuned threshold 0.75, for positive class 1.0): 0.3552\n",
      "Recall (tuned threshold 0.75, for positive class 1.0): 0.9385\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Model Performance\n",
    "# AUC-ROC\n",
    "evaluator_roc = BinaryClassificationEvaluator(\n",
    "    labelCol=\"indexedLabel\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\"\n",
    ")\n",
    "auc_roc = evaluator_roc.evaluate(predictions_with_threshold)\n",
    "print(f\"Area Under ROC (AUC-ROC): {auc_roc:.4f}\")\n",
    "\n",
    "# AUC-PR\n",
    "evaluator_pr = BinaryClassificationEvaluator(\n",
    "    labelCol=\"indexedLabel\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderPR\"\n",
    ")\n",
    "auc_pr = evaluator_pr.evaluate(predictions_with_threshold)\n",
    "print(f\"Area Under PR (AUC-PR): {auc_pr:.4f}\")\n",
    "\n",
    "# F1 Score with tuned threshold\n",
    "evaluator_f1_tuned = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"indexedLabel\", predictionCol=\"tuned_prediction\", metricName=\"f1\"\n",
    ")\n",
    "f1_score_tuned = evaluator_f1_tuned.evaluate(predictions_with_threshold)\n",
    "print(f\"F1 Score (tuned threshold {chosen_threshold}): {f1_score_tuned:.4f}\")\n",
    "\n",
    "# Precision with tuned threshold\n",
    "evaluator_precision_tuned = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"indexedLabel\", predictionCol=\"tuned_prediction\", metricName=\"precisionByLabel\"\n",
    ")\n",
    "precision_tuned = evaluator_precision_tuned.evaluate(predictions_with_threshold, {evaluator_precision_tuned.metricLabel: 1.0})\n",
    "print(f\"Precision (tuned threshold {chosen_threshold}, for positive class 1.0): {precision_tuned:.4f}\")\n",
    "\n",
    "# Recall with tuned threshold\n",
    "evaluator_recall_tuned = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"indexedLabel\", predictionCol=\"tuned_prediction\", metricName=\"recallByLabel\"\n",
    ")\n",
    "recall_tuned = evaluator_recall_tuned.evaluate(predictions_with_threshold, {evaluator_recall_tuned.metricLabel: 1.0})\n",
    "print(f\"Recall (tuned threshold {chosen_threshold}, for positive class 1.0): {recall_tuned:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b09bb32-898d-43ba-bb86-7b01cdddad2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
