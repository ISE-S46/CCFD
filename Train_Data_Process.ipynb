{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3db2f6fc-2735-40a9-9f25-7905cb675b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- trans_date_trans_time: timestamp (nullable = true)\n",
      " |-- cc_num: long (nullable = true)\n",
      " |-- merchant: string (nullable = true)\n",
      " |-- category: string (nullable = true)\n",
      " |-- amt: double (nullable = true)\n",
      " |-- first: string (nullable = true)\n",
      " |-- last: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- street: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- zip: integer (nullable = true)\n",
      " |-- lat: double (nullable = true)\n",
      " |-- long: double (nullable = true)\n",
      " |-- city_pop: integer (nullable = true)\n",
      " |-- job: string (nullable = true)\n",
      " |-- dob: timestamp (nullable = true)\n",
      " |-- trans_num: string (nullable = true)\n",
      " |-- unix_time: integer (nullable = true)\n",
      " |-- merch_lat: double (nullable = true)\n",
      " |-- merch_long: double (nullable = true)\n",
      " |-- is_fraud: integer (nullable = true)\n",
      "\n",
      "+---+---------------------+----------------+--------------------+-------------+------+---------+-------+------+--------------------+--------------+-----+-----+-------+---------+--------+--------------------+-------------------+--------------------+----------+------------------+-----------+--------+\n",
      "|_c0|trans_date_trans_time|          cc_num|            merchant|     category|   amt|    first|   last|gender|              street|          city|state|  zip|    lat|     long|city_pop|                 job|                dob|           trans_num| unix_time|         merch_lat| merch_long|is_fraud|\n",
      "+---+---------------------+----------------+--------------------+-------------+------+---------+-------+------+--------------------+--------------+-----+-----+-------+---------+--------+--------------------+-------------------+--------------------+----------+------------------+-----------+--------+\n",
      "|  0|  2019-01-01 00:00:18|2703186189652095|fraud_Rippin, Kub...|     misc_net|  4.97| Jennifer|  Banks|     F|      561 Perry Cove|Moravian Falls|   NC|28654|36.0788| -81.1781|    3495|Psychologist, cou...|1988-03-09 00:00:00|0b242abb623afc578...|1325376018|         36.011293| -82.048315|       0|\n",
      "|  1|  2019-01-01 00:00:44|    630423337322|fraud_Heller, Gut...|  grocery_pos|107.23|Stephanie|   Gill|     F|43039 Riley Green...|        Orient|   WA|99160|48.8878|-118.2105|     149|Special education...|1978-06-21 00:00:00|1f76529f857473494...|1325376044|49.159046999999994|-118.186462|       0|\n",
      "|  2|  2019-01-01 00:00:51|  38859492057661|fraud_Lind-Buckridge|entertainment|220.11|   Edward|Sanchez|     M|594 White Dale Su...|    Malad City|   ID|83252|42.1808| -112.262|    4154|Nature conservati...|1962-01-19 00:00:00|a1a22d70485983eac...|1325376051|         43.150704|-112.154481|       0|\n",
      "|  3|  2019-01-01 00:01:16|3534093764340240|fraud_Kutch, Herm...|gas_transport|  45.0|   Jeremy|  White|     M|9443 Cynthia Cour...|       Boulder|   MT|59632|46.2306|-112.1138|    1939|     Patent attorney|1967-01-12 00:00:00|6b849c168bdad6f86...|1325376076|         47.034331|-112.561071|       0|\n",
      "|  4|  2019-01-01 00:03:06| 375534208663984| fraud_Keeling-Crist|     misc_pos| 41.96|    Tyler| Garcia|     M|    408 Bradley Rest|      Doe Hill|   VA|24433|38.4207| -79.4629|      99|Dance movement ps...|1986-03-28 00:00:00|a41d7549acf907893...|1325376186|         38.674999| -78.632459|       0|\n",
      "+---+---------------------+----------------+--------------------+-------------+------+---------+-------+------+--------------------+--------------+-----+-----+-------+---------+--------+--------------------+-------------------+--------------------+----------+------------------+-----------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.appName(\"FraudDetection\").getOrCreate()\n",
    "\n",
    "# Load the dataset\n",
    "df = spark.read.csv(\"fraudTrain.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Show dataset structure\n",
    "df.printSchema()\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3b5a38ad-ecba-4886-bb6c-41e8780ed897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------------+-------+--------+--------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+--------+-------+-------+---------+---------+---------+----------+--------+\n",
      "|    _c0|trans_date_trans_time| cc_num|merchant|category|    amt|  first|   last| gender| street|   city|  state|    zip|    lat|   long|city_pop|    job|    dob|trans_num|unix_time|merch_lat|merch_long|is_fraud|\n",
      "+-------+---------------------+-------+--------+--------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+--------+-------+-------+---------+---------+---------+----------+--------+\n",
      "|1296675|              1296675|1296675| 1296675| 1296675|1296675|1296675|1296675|1296675|1296675|1296675|1296675|1296675|1296675|1296675| 1296675|1296675|1296675|  1296675|  1296675|  1296675|   1296675| 1296675|\n",
      "+-------+---------------------+-------+--------+--------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+--------+-------+-------+---------+---------+---------+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import count\n",
    "\n",
    "# Count missing values\n",
    "df.select([count(col(c)).alias(c) for c in df.columns]).show()\n",
    "\n",
    "# Replace Null value with 0\n",
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "42da8742-4206-49c8-8460-d52d67bfa90e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+----+-----------+\n",
      "|trans_date_trans_time|hour|day_of_week|\n",
      "+---------------------+----+-----------+\n",
      "|  2019-01-01 00:00:18|   0|          3|\n",
      "|  2019-01-01 00:00:44|   0|          3|\n",
      "|  2019-01-01 00:00:51|   0|          3|\n",
      "|  2019-01-01 00:01:16|   0|          3|\n",
      "|  2019-01-01 00:03:06|   0|          3|\n",
      "+---------------------+----+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import to_timestamp, hour, dayofweek\n",
    "\n",
    "# Convert transaction date to timestamp\n",
    "df = df.withColumn(\"trans_date_trans_time\", to_timestamp(col(\"trans_date_trans_time\"), \"yyyy-MM-dd HH:mm:ss\"))\n",
    "\n",
    "# Extract time-based features\n",
    "df = df.withColumn(\"hour\", hour(col(\"trans_date_trans_time\")))\n",
    "df = df.withColumn(\"day_of_week\", dayofweek(col(\"trans_date_trans_time\")))\n",
    "\n",
    "df.select(\"trans_date_trans_time\", \"hour\", \"day_of_week\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7582076f-0994-4ce0-b484-8183936017d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+--------------+------------------+\n",
      "|     cc_num|   amt|daily_spending|daily_transactions|\n",
      "+-----------+------+--------------+------------------+\n",
      "|60416207185|117.11|        117.11|                 1|\n",
      "|60416207185| 81.48|         81.48|                 1|\n",
      "|60416207185| 52.47|         52.47|                 1|\n",
      "|60416207185|  2.77|          2.77|                 1|\n",
      "|60416207185|   8.5|           8.5|                 1|\n",
      "+-----------+------+--------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import sum as spark_sum, count as spark_count\n",
    "\n",
    "# Define window by user and transaction date\n",
    "window_spec = Window.partitionBy(\"cc_num\", \"trans_date_trans_time\")\n",
    "\n",
    "# Total daily spending per user\n",
    "df = df.withColumn(\"daily_spending\", spark_sum(\"amt\").over(window_spec))\n",
    "\n",
    "# Transaction count per day\n",
    "df = df.withColumn(\"daily_transactions\", spark_count(\"cc_num\").over(window_spec))\n",
    "\n",
    "df.select(\"cc_num\", \"amt\", \"daily_spending\", \"daily_transactions\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d2c5f2aa-ad32-47f2-a5ed-1022b06d55b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+------------------+-----------+------------------+\n",
      "|    lat|     long|         merch_lat| merch_long|          distance|\n",
      "+-------+---------+------------------+-----------+------------------+\n",
      "|36.0788| -81.1781|         36.011293| -82.048315|  78.5975684882306|\n",
      "|48.8878|-118.2105|49.159046999999994|-118.186462|30.212175719210443|\n",
      "|42.1808| -112.262|         43.150704|-112.154481|108.20608258720067|\n",
      "|46.2306|-112.1138|         47.034331|-112.561071| 95.67323113819748|\n",
      "|38.4207| -79.4629|         38.674999| -78.632459|  77.5567436258178|\n",
      "+-------+---------+------------------+-----------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import radians, cos, sin, atan2, sqrt\n",
    "\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371  # Earth radius in km\n",
    "    return 2 * R * atan2(\n",
    "        sqrt(sin((radians(lat2) - radians(lat1)) / 2) ** 2 +\n",
    "             cos(radians(lat1)) * cos(radians(lat2)) *\n",
    "             sin((radians(lon2) - radians(lon1)) / 2) ** 2),\n",
    "        sqrt(1 - (sin((radians(lat2) - radians(lat1)) / 2) ** 2 +\n",
    "                  cos(radians(lat1)) * cos(radians(lat2)) *\n",
    "                  sin((radians(lon2) - radians(lon1)) / 2) ** 2))\n",
    "    )\n",
    "\n",
    "# Add a new column for distance\n",
    "df = df.withColumn(\"distance\", haversine(col(\"lat\"), col(\"long\"), col(\"merch_lat\"), col(\"merch_long\")))\n",
    "\n",
    "df.select(\"lat\", \"long\", \"merch_lat\", \"merch_long\", \"distance\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1a302da2-5b07-4011-939e-66f0da4abe06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------+----------------+\n",
      "|     category|category_index|category_encoded|\n",
      "+-------------+--------------+----------------+\n",
      "|     misc_net|          11.0| (13,[11],[1.0])|\n",
      "|  grocery_pos|           1.0|  (13,[1],[1.0])|\n",
      "|entertainment|           6.0|  (13,[6],[1.0])|\n",
      "|gas_transport|           0.0|  (13,[0],[1.0])|\n",
      "|     misc_pos|          10.0| (13,[10],[1.0])|\n",
      "+-------------+--------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder\n",
    "\n",
    "# Convert category names to numerical index\n",
    "indexer = StringIndexer(inputCol=\"category\", outputCol=\"category_index\")\n",
    "df = indexer.fit(df).transform(df)\n",
    "\n",
    "# One-hot encode category\n",
    "encoder = OneHotEncoder(inputCol=\"category_index\", outputCol=\"category_encoded\")\n",
    "df = encoder.fit(df).transform(df)\n",
    "\n",
    "df.select(\"category\", \"category_index\", \"category_encoded\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "899549db-25cd-42fa-a4e3-ff37bf7b9ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|is_fraud|count|\n",
      "+--------+-----+\n",
      "|       1| 7506|\n",
      "|       0|17532|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import when\n",
    "\n",
    "# Get fraud and non-fraud counts\n",
    "fraud_df = df.filter(df.is_fraud == 1)\n",
    "fraud_count = fraud_df.count()\n",
    "\n",
    "# Calculate how many non-fraud cases we need for a 7:3 ratio\n",
    "# If fraud is 30%, then non-fraud is 70%\n",
    "target_non_fraud_count = int((7/3) * fraud_count)\n",
    "\n",
    "# Sample non-fraud transactions to get the target count\n",
    "non_fraud_df = df.filter(df.is_fraud == 0).sample(False, target_non_fraud_count / df.filter(df.is_fraud == 0).count())\n",
    "\n",
    "# Combine balanced dataset\n",
    "df = fraud_df.union(non_fraud_df)\n",
    "# Check final distribution\n",
    "df.groupBy(\"is_fraud\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bbe518d5-a777-426a-a8e7-40a2869fd6b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----------------------------------------------------------------+\n",
      "|category_encoded|category_encoded_values                                          |\n",
      "+----------------+-----------------------------------------------------------------+\n",
      "|(13,[1],[1.0])  |[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]|\n",
      "|(13,[0],[1.0])  |[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]|\n",
      "|(13,[1],[1.0])  |[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]|\n",
      "|(13,[0],[1.0])  |[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]|\n",
      "|(13,[1],[1.0])  |[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]|\n",
      "+----------------+-----------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import ArrayType, DoubleType\n",
    "from pyspark.ml.linalg import Vectors\n",
    "\n",
    "# Define a UDF to extract values from the vector\n",
    "def extract_values(vector):\n",
    "    return vector.toArray().tolist()\n",
    "\n",
    "# Register the UDF\n",
    "extract_values_udf = udf(extract_values, ArrayType(DoubleType()))\n",
    "\n",
    "# Apply the UDF to the category_encoded column\n",
    "df = df.withColumn(\"category_encoded_values\", extract_values_udf(col(\"category_encoded\")))\n",
    "\n",
    "# Show the DataFrame to verify\n",
    "df.select(\"category_encoded\", \"category_encoded_values\").show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "29429e7d-73cc-4746-9149-d2783dfdbbef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------------------+-----------+--------------------+-------------+-------+-------+------+------+--------------------+-------------+-----+-----+-------+---------+--------+--------------------+-------------------+--------------------+----------+------------------+-------------------+--------+----+-----------+--------------+------------------+------------------+--------------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+-----------+-----------+-----------+\n",
      "|   _c0|trans_date_trans_time|     cc_num|            merchant|     category|    amt|  first|  last|gender|              street|         city|state|  zip|    lat|     long|city_pop|                 job|                dob|           trans_num| unix_time|         merch_lat|         merch_long|is_fraud|hour|day_of_week|daily_spending|daily_transactions|          distance|category_index|category_0|category_1|category_2|category_3|category_4|category_5|category_6|category_7|category_8|category_9|category_10|category_11|category_12|\n",
      "+------+---------------------+-----------+--------------------+-------------+-------+-------+------+------+--------------------+-------------+-----+-----+-------+---------+--------+--------------------+-------------------+--------------------+----------+------------------+-------------------+--------+----+-----------+--------------+------------------+------------------+--------------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+-----------+-----------+-----------+\n",
      "|106760|  2019-03-02 23:11:08|60416207185|  fraud_Parker-Kunde|personal_care|  20.41|   Mary|  Diaz|     F|    9886 Anita Drive|Fort Washakie|   WY|82514|43.0048|-108.8964|    1645|Information syste...|1986-02-17 00:00:00|293c908b5276ad02a...|1330729868|         42.132393|-109.69481999999999|       1|  23|          7|         20.41|                 1|116.98342957838344|           8.0|       0.0|       0.0|       0.0|       0.0|       0.0|       0.0|       0.0|       0.0|       1.0|       0.0|        0.0|        0.0|        0.0|\n",
      "|106835|  2019-03-02 23:43:40|60416207185|   fraud_Berge-Hills|    kids_pets|  19.23|   Mary|  Diaz|     F|    9886 Anita Drive|Fort Washakie|   WY|82514|43.0048|-108.8964|    1645|Information syste...|1986-02-17 00:00:00|2285e041091c98cf8...|1330731820|42.995377000000005|        -109.128294|       1|  23|          7|         19.23|                 1|18.887326963782808|           4.0|       0.0|       0.0|       0.0|       0.0|       1.0|       0.0|       0.0|       0.0|       0.0|       0.0|        0.0|        0.0|        0.0|\n",
      "|212856|  2019-04-18 22:07:52|60422928733|fraud_Reichert, H...| shopping_net| 877.57|Jeffrey|Powers|     M|38352 Parrish Roa...|North Augusta|   SC|29860|33.6028| -81.9748|   46944|Secondary school ...|1942-04-02 00:00:00|5a6877b96c2410132...|1334786872|34.106508000000005|         -81.443896|       1|  22|          5|        877.57|                 1| 74.43446018543847|           5.0|       0.0|       0.0|       0.0|       0.0|       0.0|       1.0|       0.0|       0.0|       0.0|       0.0|        0.0|        0.0|        0.0|\n",
      "|132278|  2019-03-14 02:21:34|60423098130|   fraud_Bradtke PLC|  grocery_pos| 317.39|  Jason|  Gray|     M|       875 Amy Point|      Amorita|   OK|73719|36.9412| -98.2458|      83|   Barrister's clerk|1958-07-28 00:00:00|bdd9d9fb1630059e6...|1331691694|         37.475705|         -98.333904|       1|   2|          5|        317.39|                 1| 59.94420126750621|           1.0|       0.0|       1.0|       0.0|       0.0|       0.0|       0.0|       0.0|       0.0|       0.0|       0.0|        0.0|        0.0|        0.0|\n",
      "|133835|  2019-03-14 22:37:32|60423098130|fraud_Greenholt, ...| shopping_net|1042.06|  Jason|  Gray|     M|       875 Amy Point|      Amorita|   OK|73719|36.9412| -98.2458|      83|   Barrister's clerk|1958-07-28 00:00:00|b62e92b920e75a7c3...|1331764652|36.255976000000004|         -98.304663|       1|  22|          5|       1042.06|                 1| 76.37441112979597|           5.0|       0.0|       0.0|       0.0|       0.0|       0.0|       1.0|       0.0|       0.0|       0.0|       0.0|        0.0|        0.0|        0.0|\n",
      "+------+---------------------+-----------+--------------------+-------------+-------+-------+------+------+--------------------+-------------+-----+-----+-------+---------+--------+--------------------+-------------------+--------------------+----------+------------------+-------------------+--------+----+-----------+--------------+------------------+------------------+--------------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+-----------+-----------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Number of categories (replace with the actual number of categories in your dataset)\n",
    "num_categories = 13\n",
    "\n",
    "# Create separate columns for each category\n",
    "for i in range(num_categories):\n",
    "    df = df.withColumn(f\"category_{i}\", col(\"category_encoded_values\").getItem(i))\n",
    "\n",
    "# Drop the intermediate columns (if no longer needed)\n",
    "df = df.drop(\"category_encoded\", \"category_encoded_values\")\n",
    "\n",
    "# Show the DataFrame to verify\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9a7fe2d4-d8e9-4012-a919-a2b7e138f5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame as a single CSV file\n",
    "df.coalesce(1).write.csv(\"train_processed_data.csv\", header=True, mode=\"overwrite\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
