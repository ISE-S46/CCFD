FROM spark:4.0.0-python3

USER root

RUN /opt/spark/bin/spark-shell --packages org.apache.spark:spark-sql-kafka-0-10_2.13:4.0.0 --repositories https://repos.spark-packages.org/ || true

WORKDIR /app
COPY consumer_requirements.txt .
RUN pip install --no-cache-dir -r consumer_requirements.txt
COPY Pipeline /app/Pipeline
COPY consumer.py .

RUN mkdir -p /home/sparkuser && \
    mkdir -p /home/sparkuser/.ivy2 && \
    mkdir -p /app/spark_checkpoints && \
    chown -R 1001:1001 /home/sparkuser && \
    chown -R 1001:1001 /app && \
    chown -R 1001:1001 /tmp && \
    chmod -R 755 /home/sparkuser && \
    chmod -R 755 /app && \
    chmod -R 755 /tmp

RUN echo "sparkuser:x:1001:1001::/home/sparkuser:/bin/bash" >> /etc/passwd
USER 1001

ENV USER=sparkuser
ENV HOME=/home/sparkuser
ENV HADOOP_USER_NAME=sparkuser
ENV SPARK_HOME=/opt/spark
ENV PATH=$SPARK_HOME/bin:$PATH
ENV PYTHONPATH=$SPARK_HOME/python:$SPARK_HOME/python/lib/py4j-0.10.9.7-src.zip:$PYTHONPATH
ENV IVY_HOME=/home/sparkuser/.ivy2
ENV _JAVA_OPTIONS=-Duser.home=/home/sparkuser